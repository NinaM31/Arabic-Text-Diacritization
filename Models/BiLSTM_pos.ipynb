{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTwVx-i4B_Dn"
   },
   "source": [
    "# 1- Setup Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-KshqcWmWrF",
    "outputId": "ad31a80b-1b7f-4cfc-b43d-634167603ac4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PoBoeJn_mWn1",
    "outputId": "2f572539-64cd-4ac7-bdab-79b1471fc41c"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/ATD-WSD\n",
    "\n",
    "# # Create dir to for storing trained model\n",
    "# #!mkdir Baseline-w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tch6Y_RWmWkx",
    "outputId": "23a909e8-b3ce-4fc5-b4b7-166b7fd96d95"
   },
   "outputs": [],
   "source": [
    "# !pip install numpy==1.23.1\n",
    "# !pip install tensorflow==2.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pVmQYpAWmWhy"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Embedding, Dense, Dropout, LSTM, Bidirectional, TimeDistributed, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from rich import print_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqoGoZ2VmWex",
    "outputId": "d4dd499a-4117-4f5b-c609-4122ef5f2f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"GPU device not found: working on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lklEh4uKCii9"
   },
   "source": [
    "# 2- Importing Dataset\n",
    "The dataset that was prepared using Gemini which is 20% of the train, 100% val and testing taken from [original dataset](https://github.com/AliOsm/arabic-text-diacritization/tree/master/dataset)\n",
    "```\n",
    "[{\n",
    "    \"sentence\": \"some text in arabic\",\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"word\": \"word_1\",\n",
    "        \"word_sense\": \"definition_1\"\n",
    "        \"pos\" : \"part_of_speech_1\"\n",
    "      }\n",
    "    ]\n",
    "}]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Blt3y72LmWbr"
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def read_json(file_path):\n",
    "  with open(file_path, mode=\"r\", encoding=\"utf-8\") as json_data:\n",
    "    return json.load(json_data)\n",
    "\n",
    "def get_sentences(data):\n",
    "  sentences = []\n",
    "  for s in data:\n",
    "    sentences.append(s['sentence'])\n",
    "  return sentences\n",
    "\n",
    "def pprint(json_data):\n",
    "  print_json(data=json_data, highlight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "OwGB9ooSmWYT",
    "outputId": "04fa648b-4781-4fb4-ceea-1871a0708292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 10485\n",
      "Train Sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{\n",
       "  \"sentence\": \"فَاسِدٌ\",\n",
       "  \"words\": [\n",
       "    {\n",
       "      \"pos\": \"adjective\",\n",
       "      \"sense\": \"corrupt\",\n",
       "      \"word\": \"فَاسِدٌ\"\n",
       "    }\n",
       "  ]\n",
       "}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "{\n",
       "  \"sentence\": \"فَاسِدٌ\",\n",
       "  \"words\": [\n",
       "    {\n",
       "      \"pos\": \"adjective\",\n",
       "      \"sense\": \"corrupt\",\n",
       "      \"word\": \"فَاسِدٌ\"\n",
       "    }\n",
       "  ]\n",
       "}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data length: 2517\n",
      "Val Sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{\n",
       "  \"sentence\": \"وَلَوْ لَمْ تَزِدْ( 26 / 106 )\",\n",
       "  \"words\": [\n",
       "    {\n",
       "      \"word\": \"وَلَوْ\",\n",
       "      \"pos\": \"conjunction\",\n",
       "      \"sense\": \"even if\"\n",
       "    },\n",
       "    {\n",
       "      \"word\": \"لَمْ\",\n",
       "      \"pos\": \"negative particle\",\n",
       "      \"sense\": \"not\"\n",
       "    },\n",
       "    {\n",
       "      \"word\": \"تَزِدْ\",\n",
       "      \"pos\": \"verb\",\n",
       "      \"sense\": \"to increase\"\n",
       "    }\n",
       "  ]\n",
       "}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "{\n",
       "  \"sentence\": \"وَلَوْ لَمْ تَزِدْ( 26 / 106 )\",\n",
       "  \"words\": [\n",
       "    {\n",
       "      \"word\": \"وَلَوْ\",\n",
       "      \"pos\": \"conjunction\",\n",
       "      \"sense\": \"even if\"\n",
       "    },\n",
       "    {\n",
       "      \"word\": \"لَمْ\",\n",
       "      \"pos\": \"negative particle\",\n",
       "      \"sense\": \"not\"\n",
       "    },\n",
       "    {\n",
       "      \"word\": \"تَزِدْ\",\n",
       "      \"pos\": \"verb\",\n",
       "      \"sense\": \"to increase\"\n",
       "    }\n",
       "  ]\n",
       "}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = read_json(\"../Dataset/10485_train_wsd.json\")\n",
    "val_data = read_json(\"../Dataset/2517_val_wsd.json\")\n",
    "# train_data = train_data[:-6485]\n",
    "# val_data = val_data[:-2100]\n",
    "print('Training data length:', len(train_data))\n",
    "print(\"Train Sample\")\n",
    "pprint(train_data[100])\n",
    "\n",
    "print('Validation data length:', len(val_data))\n",
    "print(\"Val Sample\")\n",
    "pprint(val_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5hK3htvKgvM"
   },
   "source": [
    "# 3- Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9sdWVjt1Qv67"
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def CHAR_IDX(LIST):\n",
    "    char2idx = {}\n",
    "    idx2char = {}\n",
    "\n",
    "    for i, char in enumerate(LIST):\n",
    "        char2idx[char] = i\n",
    "        idx2char[i] = char\n",
    "\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "smVTAeOjKggL"
   },
   "outputs": [],
   "source": [
    "DIC = {\"sentence\": \"\", \"words\": \"\"}  \n",
    "ARABIC_CHAR = \"ىعظحرسيشضقثلصطكآماإهزءأفؤغجئدةخوبذتن\"\n",
    "NUMBERS = \"0123456789٠١٢٣٤٥٦٧٨٩\"\n",
    "\n",
    "# 15 possible Diacritics\n",
    "FATHATAN = u'\\u064b'\n",
    "DAMMATAN = u'\\u064c'\n",
    "KASRATAN = u'\\u064d'\n",
    "FATHA = u'\\u064e'\n",
    "DAMMA = u'\\u064f'\n",
    "KASRA = u'\\u0650'\n",
    "SHADDA = u'\\u0651'\n",
    "SUKUN = u'\\u0652'\n",
    "\n",
    "DIACRITICS = [\n",
    "    \"\",              # No Diacritic\n",
    "    FATHA,           # Fatha\n",
    "    FATHATAN,        # Fathatah\n",
    "    DAMMA,           # Damma\n",
    "    DAMMATAN,        # Dammatan\n",
    "    KASRA,           # Kasra\n",
    "    KASRATAN,        # Kasratan\n",
    "    SUKUN,           # Sukun\n",
    "    SHADDA,          # Shadda\n",
    "    SHADDA+FATHA,    # Shadda + Fatha\n",
    "    SHADDA+FATHATAN, # Shadda + Fathatah\n",
    "    SHADDA+DAMMA,    # Shadda + Damma\n",
    "    SHADDA+DAMMATAN, # Shadda + Dammatan\n",
    "    SHADDA+KASRA,    # Shadda + Kasra\n",
    "    SHADDA+KASRATAN  # Shadda + Kasratan\n",
    "]\n",
    "\n",
    "PUNCTUATIONS = [\n",
    "    \".\",    \"،\",    \":\",    \"؛\",\n",
    "    \"-\",    \"–\",    \"«\",    \"»\",\n",
    "    \"~\",    \"؟\",    \"!\",    \"*\",\n",
    "    \"(\",    \")\",    \"[\",    \"]\",\n",
    "    \"{\",    \"}\",    \";\",    \"\\n\",\n",
    "    \"'\",    \"\\\"\",   \"`\",    \"/\",\n",
    "    \",\",    \"?\",    '’',    '“',\n",
    "    '…',    '﴾',    '﴿',    \"+\",\n",
    "    \"*\",    \"=\",    \"&\",    \"_\",\n",
    "    \"\\n\",   \"\\u200d\",       \"\\u200f\"\n",
    "]\n",
    "\n",
    "\n",
    "# Special Tokens\n",
    "UNK_TOKEN = \"u\"\n",
    "PAD_TOKEN = \"p\"\n",
    "SOS_TOKEN = \"s\"\n",
    "EOS_TOKEN = \"e\"\n",
    "SPECIAL_TOKENS = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN]\n",
    "\n",
    "# Combine\n",
    "ARABIC_CHAR_SPACE = list(ARABIC_CHAR) + [' ']\n",
    "ARABIC_CHAR_VALID = ARABIC_CHAR_SPACE + DIACRITICS\n",
    "ALLCHARS = ARABIC_CHAR_SPACE + list(NUMBERS) + PUNCTUATIONS + SPECIAL_TOKENS\n",
    "CLASSES = DIACRITICS + SPECIAL_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4RjJXjyLw2e",
    "outputId": "baf58c49-4c5c-4566-f3e5-173b18aa7aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char Mapping Size: 98\n",
      "Class Mapping Size: 19\n"
     ]
    }
   ],
   "source": [
    "char_mapping, reverse_char_mapping = CHAR_IDX(ALLCHARS)\n",
    "class_mapping, reverse_class_mapping = CHAR_IDX(CLASSES)\n",
    "\n",
    "print(\"Char Mapping Size:\", len(char_mapping))\n",
    "print(\"Class Mapping Size:\", len(class_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge171xcVEiUj"
   },
   "source": [
    "# 4- Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pKp_49w2mWSl"
   },
   "outputs": [],
   "source": [
    "def remove_diacritics_line(data):\n",
    "    return data.translate(str.maketrans('', '', ''.join(DIACRITICS)))\n",
    "\n",
    "def get_max_size(data):\n",
    "  return max(len(remove_diacritics_line(item['sentence'].strip())) for item in data)\n",
    "\n",
    "def get_min_size(data):\n",
    "  return min(len(remove_diacritics_line(item['sentence'].strip())) for item in data)\n",
    "\n",
    "def one_hot_matrix(data, size):\n",
    "    one_hot_matrix = [[1 if j == i else 0 for j in range(size)] for i in data]\n",
    "    return one_hot_matrix\n",
    "\n",
    "def one_hot_vector(index , size):\n",
    "    one_hot_vector = [1 if j == index else 0 for j in range(size)]\n",
    "    return one_hot_vector\n",
    "\n",
    "# def get_words(l, line):\n",
    "#   last_word = \"\"\n",
    "#   first_word = \"\"\n",
    "#   list_of_words = []\n",
    "\n",
    "#   for i, w in enumerate(l.split()):\n",
    "#     if i == 0:\n",
    "#       first_word = w\n",
    "#     if w not in PUNCTUATIONS:\n",
    "#       last_word = w\n",
    "#   found_first = False\n",
    "#   if \"words\" not in line:\n",
    "#     return {\"sentence\": l, \"words\": []}\n",
    "#   for j, w in enumerate(line['words']):\n",
    "#     if \"word\" not in w:\n",
    "#       continue\n",
    "#     if w['word'] == first_word:\n",
    "#       found_first = True\n",
    "\n",
    "#     if found_first:\n",
    "#       list_of_words.append(w)\n",
    "#       if w['word'] == last_word:\n",
    "#         dic = {\"sentence\": l, \"words\": list_of_words}\n",
    "#         return dic\n",
    "#   dic = {\"sentence\": l, \"words\": list_of_words}\n",
    "#   return dic\n",
    "\n",
    "# def split_at(line, at='\\n'):\n",
    "#   new_data = []\n",
    "#   for l in line['sentence'].split(at):\n",
    "#     new_data.append(get_words(l, line))\n",
    "#   return new_data\n",
    "\n",
    "def punc_split(data):\n",
    "  new_data = []\n",
    "  for line in data:\n",
    "    line['sentence'] = line['sentence'].replace('.', '.\\n')\n",
    "    line['sentence'] = line['sentence'].replace(',', ',\\n')\n",
    "    line['sentence'] = line['sentence'].replace('،', '،\\n')\n",
    "    line['sentence'] = line['sentence'].replace(':', ':\\n')\n",
    "    line['sentence'] = line['sentence'].replace(';', ';\\n')\n",
    "    line['sentence'] = line['sentence'].replace('؛', '؛\\n')\n",
    "    line['sentence'] = line['sentence'].replace('(', '\\n(')\n",
    "    line['sentence'] = line['sentence'].replace(')', ')\\n')\n",
    "    line['sentence'] = line['sentence'].replace('[', '\\n[')\n",
    "    line['sentence'] = line['sentence'].replace(']', ']\\n')\n",
    "    line['sentence'] = line['sentence'].replace('{', '\\n{')\n",
    "    line['sentence'] = line['sentence'].replace('}', '}\\n')\n",
    "    line['sentence'] = line['sentence'].replace('«', '\\n«')\n",
    "    line['sentence'] = line['sentence'].replace('»', '»\\n')\n",
    "    line['sentence'] = line['sentence'].replace('؟', '؟\\n')\n",
    "    line['sentence'] = line['sentence'].replace('?', '?\\n')\n",
    "    line['sentence'] = line['sentence'].replace('!', '!\\n')\n",
    "    line['sentence'] = line['sentence'].replace('-', '-\\n')\n",
    "\n",
    "     \n",
    "    # new_data.append(dic)  \n",
    "    for l in line['sentence'].split('\\n'):\n",
    "      words = []\n",
    "      if 'words' in line:\n",
    "          words = line['words']\n",
    "      new_data.append({\"sentence\": l, \"words\": words} )   \n",
    "      # a = get_words(l, line)\n",
    "      # if a and len(a) > 0:\n",
    "      # new_data.append(a)\n",
    "        \n",
    "  return new_data\n",
    "\n",
    "def split_on_length(sentence_data, max_len=500):\n",
    "    split_sentences = []\n",
    "\n",
    "    for sentence in punc_split(sentence_data):\n",
    "       new_sentence = remove_diacritics_line(sentence['sentence']).strip()\n",
    "       \n",
    "       if len(new_sentence) != 0:\n",
    "          if len(new_sentence) > 0 and len(new_sentence) <= max_len:\n",
    "                  #sentence['sentence'] = sentence['sentence'].strip()\n",
    "                  #split_sentences.append(sentence)\n",
    "                  # dic = \n",
    "                  split_sentences.append({\"sentence\": sentence['sentence'].strip(), \"words\": sentence['words']})\n",
    "          else:\n",
    "            sentence_words = sentence['sentence'].split()\n",
    "            temp_sentence = ''\n",
    "\n",
    "            for word in sentence_words:\n",
    "              if len(remove_diacritics_line(temp_sentence).strip()) + len(remove_diacritics_line(word).strip()) + 1 > max_len:\n",
    "                  if len(remove_diacritics_line(temp_sentence).strip()) > 0:\n",
    "                      # dic = {\"sentence\": temp_sentence.strip(), \"words\": sentence['words']}\n",
    "                      split_sentences.append({\"sentence\": temp_sentence.strip(), \"words\": sentence['words']})\n",
    "                      # a = re.sub(temp_sentence, f'{temp_sentence}\\\\n', sentence['sentence'])\n",
    "                      # dic = {\"sentence\": a.strip(), \"words\": sentence['words']}\n",
    "                      # n = split_at(dic)\n",
    "                      # for i in n:\n",
    "                      #   if len(i['sentence']) <= max_len:\n",
    "                      #     i['sentence'] = i['sentence'].strip()\n",
    "                      #     split_sentences.append(i)\n",
    "                  temp_sentence = word\n",
    "              else:\n",
    "                  temp_sentence = word if temp_sentence == '' else temp_sentence + ' ' + word\n",
    "\n",
    "            if len(remove_diacritics_line(temp_sentence).strip()) > 0:\n",
    "                  # dic = {\"sentence\": temp_sentence.strip(), \"words\": sentence['words']}\n",
    "                  split_sentences.append({\"sentence\": temp_sentence.strip(), \"words\": sentence['words']})\n",
    "                  # a = re.sub(temp_sentence, f'{temp_sentence}\\\\n', sentence['sentence'])\n",
    "                  # dic = {\"sentence\": a.strip(), \"words\": sentence['words']}\n",
    "\n",
    "                  # #sentence['sentence'] = re.sub(temp_sentence, f'{temp_sentence}\\\\n', sentence['sentence'])\n",
    "                  # n = split_at(dic)\n",
    "                  # for i in n:\n",
    "                  #   if len(i['sentence']) <= max_len:\n",
    "                  #     i['sentence'] = i['sentence'].strip()\n",
    "                  #     split_sentences.append(i)\n",
    "\n",
    "    return split_sentences\n",
    "def get_all_pos(docs):\n",
    "    sense = []\n",
    "    for doc in docs:\n",
    "      for word in doc['words']:\n",
    "        if 'pos' in word:\n",
    "          sense.append(word['pos'])\n",
    "    return sense\n",
    "\n",
    "def train_word_embeddings(docs):\n",
    "    # doc = get_sentences(docs)\n",
    "    doc = get_all_pos(docs)\n",
    "    \n",
    "    \n",
    "    # doc.extend(words)\n",
    "    tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(doc)\n",
    "\n",
    "    sentences = [dc.split() for dc in doc ]\n",
    "    sentences.append([UNK_TOKEN])\n",
    "   \n",
    "    # sentences.append([DIAC_TOKEN])\n",
    "    print(len(sentences))\n",
    "    word2vec_model = Word2Vec(sentences, vector_size = 300, window=5, min_count=1, workers=4)\n",
    "\n",
    "    word_embeddings = word2vec_model.wv\n",
    "\n",
    "    return word_embeddings, tokenizer\n",
    "\n",
    "def get_word_embeddings(word):\n",
    "    encoded_docs = tokenizer.texts_to_sequences(word)\n",
    "    word_embeddings_for_sample = []\n",
    "    for word_index in encoded_docs:\n",
    "      if len(word_index) > 0:\n",
    "        if word_index[0] in data_embeddings:\n",
    "          word_embeddings_for_sample.append(data_embeddings[word_index[0]])\n",
    "    return word_embeddings_for_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YTSfJP5oL6P"
   },
   "source": [
    "# 5- Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVqH68dByDKY",
    "outputId": "ca17bcd0-a2da-44f2-cece-41f99ca6b1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: 35722\n",
      "Training data max: 500\n",
      "Training data min: 1\n",
      "Train Sample: [{'sentence': 'وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا ،', 'words': [{'pos': 'conjunction', 'sense': 'even if', 'word': 'وَلَوْ'}, {'pos': 'verb', 'sense': 'to gather', 'word': 'جَمَعَ'}, {'pos': 'adverb', 'sense': 'then', 'word': 'ثُمَّ'}, {'pos': 'verb', 'sense': 'to know', 'word': 'عَلِمَ'}, {'pos': 'noun', 'sense': 'leaving', 'word': 'تَرْكَ'}, {'pos': 'noun', 'sense': 'pillar', 'word': 'رُكْنٍ'}, {'pos': 'preposition', 'sense': 'from', 'word': 'مِنْ'}, {'pos': 'adjective', 'sense': 'first', 'word': 'الْأُولَى'}, {'pos': 'verb', 'sense': 'to become invalid', 'word': 'بَطَلَتَا'}, {'pos': 'verb', 'sense': 'to return', 'word': 'وَيُعِيدُهُمَا'}, {'pos': 'adjective', 'sense': 'gathering', 'word': 'جَامِعًا'}, {'pos': 'conjunction', 'sense': 'or', 'word': 'أَوْ'}, {'pos': 'preposition', 'sense': 'from', 'word': 'مِنْ'}, {'pos': 'adjective', 'sense': 'second', 'word': 'الثَّانِيَةِ'}, {'pos': 'conjunction', 'sense': 'if', 'word': 'فَإِنْ'}, {'pos': 'negative', 'sense': 'not', 'word': 'لَمْ'}, {'pos': 'verb', 'sense': 'to be late', 'word': 'يَطُلْ'}, {'pos': 'verb', 'sense': 'to make amends', 'word': 'تَدَارَكَ'}, {'pos': 'conjunction', 'sense': 'otherwise', 'word': 'وَإِلَّا'}, {'pos': 'adjective', 'sense': 'invalid', 'word': 'فَبَاطِلَةٌ'}, {'pos': 'negative', 'sense': 'not', 'word': 'وَلَا'}, {'pos': 'verb', 'sense': 'to gather', 'word': 'جَمَعَ'}, {'pos': 'conjunction', 'sense': 'even if', 'word': 'وَلَوْ'}, {'pos': 'verb', 'sense': 'to be ignorant', 'word': 'جَهِلَ'}, {'pos': 'verb', 'sense': 'to return', 'word': 'أَعَادَهُمَا'}, {'pos': 'preposition', 'sense': 'for', 'word': 'لِ'}, {'pos': 'noun', 'sense': 'times', 'word': 'وَقْتَيْهِمَا'}]}]\n",
      "\n",
      "Val Data Size: 15120\n",
      "Validation data max: 500\n",
      "Validation data min: 1\n"
     ]
    }
   ],
   "source": [
    "split_length_train_data      = split_on_length(train_data)\n",
    "split_length_val_data      = split_on_length(val_data)\n",
    "\n",
    "print(\"Train Data Size:\", len(split_length_train_data))\n",
    "print('Training data max:', get_max_size(split_length_train_data))\n",
    "print('Training data min:', get_min_size(split_length_train_data))\n",
    "print(\"Train Sample:\", split_length_train_data[0:1])\n",
    "print()\n",
    "\n",
    "print(\"Val Data Size:\", len(split_length_val_data))\n",
    "print('Validation data max:', get_max_size(split_length_val_data))\n",
    "print('Validation data min:', get_min_size(split_length_val_data))\n",
    "# print(\"Val Sample:\", split_length_val_data[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCucn8BZ8nzE"
   },
   "source": [
    "#### Data without diacritics and without punc and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hHz280qHoBuL",
    "outputId": "da5d5c35-7fd3-4187-ab7e-75f66b29462e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 31578\n",
      "Validation data length: 13458\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[\n",
       "  {\n",
       "    \"sentence\": \"وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  },\n",
       "  {\n",
       "    \"sentence\": \"أَوْ مِنْ الثَّانِيَةِ\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[\n",
       "  {\n",
       "    \"sentence\": \"وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  },\n",
       "  {\n",
       "    \"sentence\": \"أَوْ مِنْ الثَّانِيَةِ\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_data(data, remove_dia=False):\n",
    "  cleaned_data = []\n",
    "  for text in data:\n",
    "    temp = {'sentence': \"\", 'words':[]}\n",
    "    sen = text['sentence']\n",
    "    cleaned = ''.join(char for char in sen if char in ARABIC_CHAR_VALID)\n",
    "    cleaned = cleaned.strip()\n",
    "    if cleaned != \"\":\n",
    "      if remove_dia:\n",
    "        cleaned = remove_diacritics_line(cleaned)\n",
    "\n",
    "      temp['sentence'] = cleaned\n",
    "      temp['words'] = text['words']\n",
    "      cleaned_data.append(temp)\n",
    "  return cleaned_data\n",
    "\n",
    "\n",
    "clean_diac_train_data = clean_data(split_length_train_data)\n",
    "clean_diac_val_data = clean_data(split_length_val_data)\n",
    "\n",
    "print('Training data length:', len(clean_diac_train_data))\n",
    "print('Validation data length:', len(clean_diac_val_data))\n",
    "\n",
    "pprint(clean_diac_train_data[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEPnoVft8dyp"
   },
   "source": [
    "#### Data with diacritics and without punc and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pQ6mag5FoBrb",
    "outputId": "c290ba0a-4a59-4fb0-d21c-e2c951561236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 31578\n",
      "Validation data length: 13458\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[\n",
       "  {\n",
       "    \"sentence\": \"ولو جمع ثم علم ترك ركن من الأولى بطلتا ويعيدهما جامعا\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  },\n",
       "  {\n",
       "    \"sentence\": \"أو من الثانية\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[\n",
       "  {\n",
       "    \"sentence\": \"ولو جمع ثم علم ترك ركن من الأولى بطلتا ويعيدهما جامعا\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  },\n",
       "  {\n",
       "    \"sentence\": \"أو من الثانية\",\n",
       "    \"words\": [\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adverb\",\n",
       "        \"sense\": \"then\",\n",
       "        \"word\": \"ثُمَّ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to know\",\n",
       "        \"word\": \"عَلِمَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"leaving\",\n",
       "        \"word\": \"تَرْكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"pillar\",\n",
       "        \"word\": \"رُكْنٍ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"first\",\n",
       "        \"word\": \"الْأُولَى\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to become invalid\",\n",
       "        \"word\": \"بَطَلَتَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"وَيُعِيدُهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"gathering\",\n",
       "        \"word\": \"جَامِعًا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"or\",\n",
       "        \"word\": \"أَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"from\",\n",
       "        \"word\": \"مِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"second\",\n",
       "        \"word\": \"الثَّانِيَةِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"if\",\n",
       "        \"word\": \"فَإِنْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"لَمْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be late\",\n",
       "        \"word\": \"يَطُلْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to make amends\",\n",
       "        \"word\": \"تَدَارَكَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"otherwise\",\n",
       "        \"word\": \"وَإِلَّا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"adjective\",\n",
       "        \"sense\": \"invalid\",\n",
       "        \"word\": \"فَبَاطِلَةٌ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"negative\",\n",
       "        \"sense\": \"not\",\n",
       "        \"word\": \"وَلَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to gather\",\n",
       "        \"word\": \"جَمَعَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"conjunction\",\n",
       "        \"sense\": \"even if\",\n",
       "        \"word\": \"وَلَوْ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to be ignorant\",\n",
       "        \"word\": \"جَهِلَ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"verb\",\n",
       "        \"sense\": \"to return\",\n",
       "        \"word\": \"أَعَادَهُمَا\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"preposition\",\n",
       "        \"sense\": \"for\",\n",
       "        \"word\": \"لِ\"\n",
       "      },\n",
       "      {\n",
       "        \"pos\": \"noun\",\n",
       "        \"sense\": \"times\",\n",
       "        \"word\": \"وَقْتَيْهِمَا\"\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean_train_data = [remove_diacritics_line(text) for text in clean_diac_train_data]\n",
    "# clean_val_data = [remove_diacritics_line(text) for text in clean_diac_val_data]\n",
    "\n",
    "clean_train_data = clean_data(split_length_train_data, remove_dia=True)\n",
    "clean_val_data = clean_data(split_length_val_data, remove_dia=True)\n",
    "\n",
    "print('Training data length:', len(clean_train_data))\n",
    "print('Validation data length:', len(clean_val_data))\n",
    "\n",
    "pprint(clean_train_data[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET_nC50K86C_"
   },
   "source": [
    "#### Train word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yP1XBrwooBmO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185385\n"
     ]
    }
   ],
   "source": [
    "data_to_embeddings = clean_train_data + clean_val_data\n",
    "data_embeddings, tokenizer = train_word_embeddings(data_to_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8Q1H6ZKacWb"
   },
   "source": [
    "# 6- Custom Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "b1dnZ-DeoBgd"
   },
   "outputs": [],
   "source": [
    "def get_sentence_classes(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    unk_emb = get_word_embeddings([UNK_TOKEN])[0]\n",
    "    sos_emb = get_word_embeddings([SOS_TOKEN])[0]\n",
    "    vec = []\n",
    "    vec = one_hot_vector(char_mapping[SOS_TOKEN], len(char_mapping))\n",
    "    vec.extend(sos_emb)\n",
    "    x.append(vec)\n",
    "    y.append(one_hot_vector(class_mapping[SOS_TOKEN],len(class_mapping)))\n",
    "\n",
    "    data_raw = data['sentence'].split()\n",
    "    for word in data_raw:\n",
    "        emb2 = []\n",
    "          \n",
    "        for s in data['words']:\n",
    "          if 'pos' in s:\n",
    "            if 'word' in s and remove_diacritics_line(s['word']) == remove_diacritics_line(word):\n",
    "              emb2 = get_word_embeddings(s['pos'])\n",
    "                \n",
    "        if (len(emb2) == 0):\n",
    "            emb = unk_emb\n",
    "        else:\n",
    "            emb = emb2[0]\n",
    "    \n",
    "        if word in PUNCTUATIONS:\n",
    "          emb = unk_emb\n",
    "        else:\n",
    "          if (len(emb2) == 0):\n",
    "            emb = unk_emb\n",
    "          else:\n",
    "            emb = emb2[0]\n",
    "                \n",
    "        for idx, char in enumerate(word):\n",
    "            if char in DIACRITICS:\n",
    "                continue\n",
    "            # e += 1\n",
    "            vec = []\n",
    "            vec = one_hot_vector(char_mapping[char], len(char_mapping))\n",
    "            vec.extend(emb)\n",
    "            x.append(vec)\n",
    "            \n",
    "            if char not in list(ARABIC_CHAR):\n",
    "                y.append(one_hot_vector(class_mapping[UNK_TOKEN],len(class_mapping)))\n",
    "            else: \n",
    "                char_diac = ''\n",
    "                if idx + 1 < len(word) and word[idx + 1] in DIACRITICS:\n",
    "                    char_diac = word[idx + 1]\n",
    "                    if idx + 2 < len(word) and word[idx + 2] in DIACRITICS and char_diac + word[idx + 2] in char_mapping:\n",
    "                        char_diac += word[idx + 2]\n",
    "                    elif idx + 2 < len(word) and word[idx + 2] in DIACRITICS and word[idx + 2] + char_diac in class_mapping:\n",
    "                        char_diac = word[idx + 2] + char_diac      \n",
    "                y.append(one_hot_vector(class_mapping[char_diac],len(class_mapping)))\n",
    "        \n",
    "        eos_emb = get_word_embeddings([EOS_TOKEN])[0]\n",
    "        vec = []\n",
    "        vec = one_hot_vector(char_mapping[EOS_TOKEN], len(char_mapping))\n",
    "        vec.extend(eos_emb)\n",
    "        x.append(vec)\n",
    "\n",
    "        y.append(one_hot_vector(class_mapping[EOS_TOKEN],len(class_mapping)))\n",
    "\n",
    "    assert(len(x) == len(y))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8K_GCQrRmWAs"
   },
   "outputs": [],
   "source": [
    "def get_classes(data):\n",
    "  X = []\n",
    "  Y = []\n",
    "\n",
    "  for sentence in data:\n",
    "    x, y = get_sentence_classes(sentence)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "  X = np.asarray(X)\n",
    "  Y = np.asarray(Y)\n",
    "  return X, Y\n",
    "\n",
    "class custom_data_generator(Sequence):\n",
    "\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.lines  = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.lines) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lines = self.lines[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch, Y_batch = get_classes(lines)\n",
    "        \n",
    "        X_max_seq_len = np.max([len(x) for x in X_batch])\n",
    "        Y_max_seq_len = np.max([len(y) for y in Y_batch])\n",
    "        \n",
    "        assert(X_max_seq_len == Y_max_seq_len)\n",
    "\n",
    "        # vec = []\n",
    "        pad_emb = get_word_embeddings([PAD_TOKEN])[0]\n",
    "        vec = []\n",
    "        # vec = one_hot_vector(eos_emb, 300)\n",
    "        vec = one_hot_vector(char_mapping[PAD_TOKEN],len(char_mapping))\n",
    "        vec.extend(pad_emb)\n",
    "        # vec.extend(vec)\n",
    "        X = []\n",
    "        for x in X_batch:\n",
    "            x = list(x)\n",
    "            x.extend([vec] * (X_max_seq_len - len(x)))\n",
    "            X.append(np.asarray(x))\n",
    "        \n",
    "        Y = []\n",
    "        for y in Y_batch:\n",
    "            padding_length = Y_max_seq_len - len(y)\n",
    "            y = list(y)\n",
    "            y.extend(one_hot_matrix([class_mapping[PAD_TOKEN]] * (padding_length), len(class_mapping)))\n",
    "            Y.append(np.asarray(y))\n",
    "\n",
    "        X, Y = np.asarray(X), np.asarray(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Y2soLOb3ohZx"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "   model = Sequential()\n",
    "   model.add(InputLayer(input_shape=(None, 398)))\n",
    "\n",
    "   model.add(Bidirectional(LSTM(units=256,return_sequences=True,kernel_initializer=glorot_normal(seed=500))))\n",
    "   model.add(Dropout(0.5))\n",
    "   model.add(Bidirectional(LSTM(units=256,return_sequences=True,kernel_initializer=glorot_normal(seed=500))))\n",
    "   model.add(Dropout(0.5))\n",
    "   model.add(Bidirectional(LSTM(units=256,return_sequences=True,kernel_initializer=glorot_normal(seed=500))))\n",
    "   model.add(TimeDistributed(Dense(units=512,activation='relu',kernel_initializer=glorot_normal(seed=500))))\n",
    "   model.add(TimeDistributed(Dense(units=512,activation='relu',kernel_initializer=glorot_normal(seed=500))))\n",
    "   model.add(TimeDistributed(Dense(units=len(class_mapping),activation='softmax',kernel_initializer=glorot_normal(seed=500))))\n",
    "   model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOMzl4wAohRq",
    "outputId": "5f31b6f2-d64c-4998-c1d6-6205ab34be2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, None, 512)        1341440   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 512)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 512)        1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 512)         0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 512)        1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 512)        262656    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 512)        262656    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 19)         9747      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,026,323\n",
      "Trainable params: 5,026,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bgf8wJQvomsF"
   },
   "outputs": [],
   "source": [
    "def fit_model(model, epochs, batch_size, train_data, val_data):\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(val_data)\n",
    "    \n",
    "    checkpoint_path = './Checkpoints/Bilstm-POS/epoch{epoch:02d}.ckpt'\n",
    "\n",
    "    checkpoint_cb = ModelCheckpoint(checkpoint_path, verbose=0)\n",
    "\n",
    "    training_generator = custom_data_generator(train_data, batch_size)\n",
    "    val_generator = custom_data_generator(val_data, batch_size)\n",
    "\n",
    "    history =  model.fit(training_generator,validation_data=val_generator,epochs=epochs,callbacks=[checkpoint_cb])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-w9KIkNcomoM",
    "outputId": "45f73415-8815-412c-afa1-a4f2e11b8a39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "494/494 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.9202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch01.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch01.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 435s 851ms/step - loss: 0.2467 - accuracy: 0.9202 - val_loss: 0.0912 - val_accuracy: 0.9702\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch02.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch02.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 415s 840ms/step - loss: 0.0879 - accuracy: 0.9707 - val_loss: 0.0531 - val_accuracy: 0.9830\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch03.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch03.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 422s 854ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.0395 - val_accuracy: 0.9874\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch04.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch04.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 427s 865ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.0341 - val_accuracy: 0.9892\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch05.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch05.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 419s 848ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0304 - val_accuracy: 0.9906\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch06.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch06.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 431s 873ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.0270 - val_accuracy: 0.9918\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch07.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch07.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 427s 865ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.0256 - val_accuracy: 0.9924\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch08.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch08.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 418s 847ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.0240 - val_accuracy: 0.9929\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch09.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch09.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 422s 854ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0230 - val_accuracy: 0.9932\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "C:\\Users\\PowerPC\\AppData\\Local\\Temp\\ipykernel_4196\\3760838992.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Y = np.asarray(Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch10.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpoints/Bilstm-POS\\epoch10.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/494 [==============================] - 431s 874ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0221 - val_accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "history = fit_model(model, 10, 64, clean_diac_train_data, clean_diac_val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewXj0HZCKjMo"
   },
   "source": [
    "# 7- Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpKJRuWNomfK",
    "outputId": "f1141484-eed4-49cf-c42c-4cf7caabdc4e"
   },
   "outputs": [],
   "source": [
    "# joblib.dump(model, 'bilstmPOS.joblib')\n",
    "# filename = 'bilstmPOS.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u5_tScRK3_M"
   },
   "source": [
    "# 8- Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2pfEp6gNbCcU"
   },
   "outputs": [],
   "source": [
    "def predict(line, model):\n",
    "    words = []\n",
    "    if \"words\" in line:\n",
    "        words = line['words']\n",
    "    dic = {\"sentence\": remove_diacritics_line(line['sentence']), \"words\": words}\n",
    "\n",
    "    X, Y = get_classes([dic])\n",
    "    \n",
    "    predictions = model.predict(X, verbose=0).squeeze()\n",
    "    predictions = predictions[1:-1]\n",
    "\n",
    "    output = ''\n",
    "    for char, prediction in zip(remove_diacritics_line(dic['sentence']), predictions): \n",
    "        output += char\n",
    "        if char not in list(ARABIC_CHAR):\n",
    "            continue\n",
    "        output += reverse_class_mapping[np.argmax(prediction)]\n",
    "    return output\n",
    "\n",
    "def predict_text(data, model, file_name):\n",
    "  for idx, line in enumerate(data):\n",
    "    output = predict(line, model)\n",
    "\n",
    "    with open(f\"{file_name}_out.txt\", 'a', encoding=\"utf-8\") as file:\n",
    "      file.write(output + \"\\n\")\n",
    "\n",
    "    with open(f\"{file_name}_inp.txt\", 'a', encoding=\"utf-8\") as file:\n",
    "      file.write(line['sentence'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "meOKesGJmV5l"
   },
   "outputs": [],
   "source": [
    "# model_file_path = 'bilstmWSD.joblib'\n",
    "# model = joblib.load(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "J1H_mVk4yS_H",
    "outputId": "af287b06-64df-4088-968b-5375859a00c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data length: 2528\n",
      "Test Sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{\n",
       "  \"sentence\": \"قَوْلُهُ لَمْ يَجُزْ لَهُ التَّيَمُّمُ ) يُتَأَمَّلُ وَجْهُ ذَلِكَ .\",\n",
       "  \"words\": [\n",
       "    {\n",
       "      \"pos\": \"noun\",\n",
       "      \"sense\": \"saying\",\n",
       "      \"word\": \"قَوْلُهُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"verb\",\n",
       "      \"sense\": \"not permitted\",\n",
       "      \"word\": \"لَمْ يَجُزْ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"preposition\",\n",
       "      \"sense\": \"for\",\n",
       "      \"word\": \"لَهُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"noun\",\n",
       "      \"sense\": \"dry ablution\",\n",
       "      \"word\": \"التَّيَمُّمُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"verb\",\n",
       "      \"sense\": \"to be contemplated\",\n",
       "      \"word\": \"يُتَأَمَّلُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"noun\",\n",
       "      \"sense\": \"face\",\n",
       "      \"word\": \"وَجْهُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"pronoun\",\n",
       "      \"sense\": \"that\",\n",
       "      \"word\": \"ذَلِكَ\"\n",
       "    }\n",
       "  ]\n",
       "}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "{\n",
       "  \"sentence\": \"قَوْلُهُ لَمْ يَجُزْ لَهُ التَّيَمُّمُ ) يُتَأَمَّلُ وَجْهُ ذَلِكَ .\",\n",
       "  \"words\": [\n",
       "    {\n",
       "      \"pos\": \"noun\",\n",
       "      \"sense\": \"saying\",\n",
       "      \"word\": \"قَوْلُهُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"verb\",\n",
       "      \"sense\": \"not permitted\",\n",
       "      \"word\": \"لَمْ يَجُزْ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"preposition\",\n",
       "      \"sense\": \"for\",\n",
       "      \"word\": \"لَهُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"noun\",\n",
       "      \"sense\": \"dry ablution\",\n",
       "      \"word\": \"التَّيَمُّمُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"verb\",\n",
       "      \"sense\": \"to be contemplated\",\n",
       "      \"word\": \"يُتَأَمَّلُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"noun\",\n",
       "      \"sense\": \"face\",\n",
       "      \"word\": \"وَجْهُ\"\n",
       "    },\n",
       "    {\n",
       "      \"pos\": \"pronoun\",\n",
       "      \"sense\": \"that\",\n",
       "      \"word\": \"ذَلِكَ\"\n",
       "    }\n",
       "  ]\n",
       "}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = read_json(\"../Dataset/2528_test_wsd.json\")\n",
    "print('Testing data length:', len(test_data))\n",
    "print(\"Test Sample\")\n",
    "pprint(test_data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BylSDBlVzs7b",
    "outputId": "37419899-e4f7-4229-ca0e-a9a3a391a103"
   },
   "outputs": [],
   "source": [
    "predict_text(test_data, model, \"./Outputs/Bilstm_pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsEXB7Dimr93"
   },
   "source": [
    "# 9- Error Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "\n",
    "def get_diacritic_class(idx, line, case_ending, arabic_letters, diacritic_classes):\n",
    "  # Handle without case ending\n",
    "  if not case_ending:\n",
    "    end = True\n",
    "    for i in range(idx + 1, len(line)):\n",
    "      if line[i] not in diacritic_classes:\n",
    "        end = line[i].isspace()\n",
    "        break\n",
    "    if end:\n",
    "      return -1\n",
    "\n",
    "  if idx + 1 >= len(line) or line[idx + 1] not in diacritic_classes:\n",
    "    # No diacritic\n",
    "    return 0\n",
    "\n",
    "  diac = line[idx + 1]\n",
    "\n",
    "  if idx + 2 >= len(line) or line[idx + 2] not in diacritic_classes:\n",
    "    # Only one diacritic\n",
    "    return diacritic_classes.index(diac) + 1\n",
    "\n",
    "  diac += line[idx + 2]\n",
    "\n",
    "  try:\n",
    "    # Try the possibility of double diacritics\n",
    "    return diacritic_classes.index(diac) + 1\n",
    "  except:\n",
    "    try:\n",
    "      # Try the possibility of reversed double diacritics\n",
    "      return diacritic_classes.index(diac[::-1]) + 1\n",
    "    except:\n",
    "      # Otherwise consider only the first diacritic\n",
    "      return diacritic_classes.index(diac[0]) + 1\n",
    "\n",
    "def get_diacritics_classes(line, case_ending, arabic_letters, diacritic_classes, style):\n",
    "  classes = list()\n",
    "  for idx, char in enumerate(line):\n",
    "    if style == 'Fadel':\n",
    "      if char in arabic_letters:\n",
    "        classes.append(get_diacritic_class(idx, line, case_ending, arabic_letters, diacritic_classes))\n",
    "    elif style == 'Zitouni':\n",
    "      if char in diacritic_classes or char.isspace():\n",
    "        continue\n",
    "      classes.append(get_diacritic_class(idx, line, case_ending, arabic_letters, diacritic_classes))\n",
    "  return classes\n",
    "\n",
    "def clear_line(line, arabic_letters, diacritic_classes):\n",
    "  line = ' '.join(''.join([char if char in list(arabic_letters) + diacritic_classes + [' '] else ' ' for char in line]).split())\n",
    "  new_line = ''\n",
    "  for idx, char in enumerate(line):\n",
    "  \tif char not in diacritic_classes or (idx > 0 and line[idx - 1] != ' '):\n",
    "  \t\tnew_line += char\n",
    "  line = new_line\n",
    "  new_line = ''\n",
    "  for idx, char in enumerate(line):\n",
    "  \tif char not in diacritic_classes or (idx > 0 and line[idx - 1] != ' '):\n",
    "  \t\tnew_line += char\n",
    "  return new_line\n",
    "\n",
    "def calculate_der(original_file, target_file, arabic_letters, diacritic_classes, style, case_ending=True, no_diacritic=True):\n",
    "  with open(original_file, 'r', encoding=\"utf8\") as file:\n",
    "    original_content = file.readlines()\n",
    "\n",
    "  with open(target_file, 'r', encoding=\"utf8\") as file:\n",
    "    target_content = file.readlines()\n",
    "\n",
    "  assert(len(original_content) == len(target_content))\n",
    "\n",
    "  equal = 0\n",
    "  not_equal = 0\n",
    "  for (original_line, target_line) in zip(original_content, target_content):\n",
    "    if style == 'Fadel':\n",
    "      original_line = clear_line(original_line, arabic_letters, diacritic_classes)\n",
    "      target_line = clear_line(target_line, arabic_letters, diacritic_classes)\n",
    "\n",
    "    original_classes = get_diacritics_classes(original_line, case_ending, arabic_letters, diacritic_classes, style)\n",
    "    target_classes = get_diacritics_classes(target_line, case_ending, arabic_letters, diacritic_classes, style)\n",
    "    if len(original_classes) != len(target_classes):\n",
    "       continue\n",
    "    assert(len(original_classes) == len(target_classes))\n",
    "\n",
    "    for (original_class, target_class) in zip(original_classes, target_classes):\n",
    "      if not no_diacritic and original_class == 0:\n",
    "        continue\n",
    "      if original_class == -1 and target_class != -1:\n",
    "        print('WOW!')\n",
    "      if original_class != -1 and target_class == -1:\n",
    "        print('WOW!')\n",
    "      if original_class == -1 and target_class == -1:\n",
    "        continue\n",
    "\n",
    "      equal += (original_class == target_class)\n",
    "      not_equal += (original_class != target_class)\n",
    "\n",
    "  return round(not_equal / max(1, (equal + not_equal)) * 100, 2)\n",
    "\n",
    "def calculate_wer(original_file, target_file, arabic_letters, diacritic_classes, style, case_ending=True, no_diacritic=True):\n",
    "  with open(original_file, 'r', encoding=\"utf8\") as file:\n",
    "    original_content = file.readlines()\n",
    "\n",
    "  with open(target_file, 'r', encoding=\"utf8\") as file:\n",
    "    target_content = file.readlines()\n",
    "\n",
    "  assert(len(original_content) == len(target_content))\n",
    "\n",
    "  equal = 0\n",
    "  not_equal = 0\n",
    "  for idx, (original_line, target_line) in enumerate(zip(original_content, target_content)):\n",
    "    if style == 'Fadel':\n",
    "      original_line = clear_line(original_line, arabic_letters, diacritic_classes)\n",
    "      target_line = clear_line(target_line, arabic_letters, diacritic_classes)\n",
    "\n",
    "    original_line = original_line.split()\n",
    "    target_line = target_line.split()\n",
    "    if len(original_line) != len(target_line):\n",
    "       continue\n",
    "    assert(len(original_line) == len(target_line))\n",
    "\n",
    "    for (original_word, target_word) in zip(original_line, target_line):\n",
    "      original_classes = get_diacritics_classes(original_word, case_ending, arabic_letters, diacritic_classes, style)\n",
    "      target_classes = get_diacritics_classes(target_word, case_ending, arabic_letters, diacritic_classes, style)\n",
    "\n",
    "      if len(original_classes) != len(target_classes):\n",
    "       continue\n",
    "      assert(len(original_classes) == len(target_classes))\n",
    "\n",
    "      if len(original_classes) == 0:\n",
    "        continue\n",
    "\n",
    "      equal_classes = 0\n",
    "      for (original_class, target_class) in zip(original_classes, target_classes):\n",
    "        if not no_diacritic and original_class == 0:\n",
    "          equal_classes += 1\n",
    "          continue\n",
    "        equal_classes += (original_class == target_class)\n",
    "\n",
    "      equal += (equal_classes == len(original_classes))\n",
    "      not_equal += (equal_classes != len(original_classes))\n",
    "\n",
    "  return round(not_equal / max(1, (equal + not_equal)) * 100, 2)\n",
    "\n",
    "def calculate_ser(original_file, target_file, arabic_letters, diacritic_classes, style, case_ending=True, no_diacritic=True):\n",
    "  with open(original_file, 'r', encoding=\"utf8\") as file:\n",
    "    original_content = file.readlines()\n",
    "\n",
    "  with open(target_file, 'r', encoding=\"utf8\") as file:\n",
    "    target_content = file.readlines()\n",
    "\n",
    "  assert(len(original_content) == len(target_content))\n",
    "\n",
    "  equal = 0\n",
    "  not_equal = 0\n",
    "  for idx, (original_line, target_line) in enumerate(zip(original_content, target_content)):\n",
    "    if style == 'Fadel':\n",
    "      original_line = clear_line(original_line, arabic_letters, diacritic_classes)\n",
    "      target_line = clear_line(target_line, arabic_letters, diacritic_classes)\n",
    "\n",
    "    original_line = original_line.split()\n",
    "    target_line = target_line.split()\n",
    "\n",
    "    assert(len(original_line) == len(target_line))\n",
    "\n",
    "    equal_words = True\n",
    "    for (original_word, target_word) in zip(original_line, target_line):\n",
    "      original_classes = get_diacritics_classes(original_word, case_ending, arabic_letters, diacritic_classes, style)\n",
    "      target_classes = get_diacritics_classes(target_word, case_ending, arabic_letters, diacritic_classes, style)\n",
    "      if len(original_classes) != len(target_classes):\n",
    "          continue\n",
    "      assert(len(original_classes) == len(target_classes))\n",
    "\n",
    "      if len(original_classes) == 0:\n",
    "        continue\n",
    "\n",
    "      equal_classes = 0\n",
    "      for (original_class, target_class) in zip(original_classes, target_classes):\n",
    "        if not no_diacritic and original_class == 0:\n",
    "          equal_classes += 1\n",
    "          continue\n",
    "        equal_classes += (original_class == target_class)\n",
    "\n",
    "      if equal_classes != len(original_classes):\n",
    "        equal_words = False\n",
    "\n",
    "    equal += equal_words\n",
    "    not_equal += not equal_words\n",
    "\n",
    "  return round(not_equal / max(1, (equal + not_equal)) * 100, 2)\n",
    "\n",
    "def cl_der(original_file_path, target_file_path, style='Fadel'):\n",
    "  print('+---------------------------------------------------------------------------------------------+')\n",
    "  print('|       |  With case ending  | Without case ending |  With case ending  | Without case ending |')\n",
    "  print('|  DER  |------------------------------------------+------------------------------------------|')\n",
    "  print('|       |          Including no diacritic          |          Excluding no diacritic          |')\n",
    "  print('|-------+------------------------------------------+------------------------------------------|')\n",
    "  print('|   %%   |        %5.2f       |        %5.2f        |        %5.2f       |        %5.2f        |' %\n",
    "        (calculate_der(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style),\n",
    "        calculate_der(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style, case_ending=False),\n",
    "        calculate_der(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style, no_diacritic=False),\n",
    "        calculate_der(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style, case_ending=False, no_diacritic=False)))\n",
    "  print('+---------------------------------------------------------------------------------------------+')\n",
    "  print('')\n",
    "  print('+---------------------------------------------------------------------------------------------+')\n",
    "  print('|       |  With case ending  | Without case ending |  With case ending  | Without case ending |')\n",
    "  print('|  WER  |------------------------------------------+------------------------------------------|')\n",
    "  print('|       |          Including no diacritic          |          Excluding no diacritic          |')\n",
    "  print('|-------+------------------------------------------+------------------------------------------|')\n",
    "  print('|   %%   |        %5.2f       |        %5.2f        |        %5.2f       |        %5.2f        |' %\n",
    "        (calculate_wer(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style),\n",
    "        calculate_wer(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style, case_ending=False),\n",
    "        calculate_wer(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style, no_diacritic=False),\n",
    "        calculate_wer(original_file_path, target_file_path, ARABIC_CHAR_SPACE, DIACRITICS, style, case_ending=False, no_diacritic=False)))\n",
    "  print('+---------------------------------------------------------------------------------------------+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------+\n",
      "|       |  With case ending  | Without case ending |  With case ending  | Without case ending |\n",
      "|  DER  |------------------------------------------+------------------------------------------|\n",
      "|       |          Including no diacritic          |          Excluding no diacritic          |\n",
      "|-------+------------------------------------------+------------------------------------------|\n",
      "|   %   |        13.00       |        11.53        |        18.37       |        16.81        |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "|       |  With case ending  | Without case ending |  With case ending  | Without case ending |\n",
      "|  WER  |------------------------------------------+------------------------------------------|\n",
      "|       |          Including no diacritic          |          Excluding no diacritic          |\n",
      "|-------+------------------------------------------+------------------------------------------|\n",
      "|   %   |        38.57       |        29.84        |        38.06       |        29.46        |\n",
      "+---------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "original_path = \"./Outputs/Bilstm_pos_inp.txt\"\n",
    "predicted_path  = \"./Outputs/Bilstm_pos_out.txt\"\n",
    "cl_der(original_path, predicted_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
